{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import feature, exposure, color\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from skimage.io import imread\n",
    "import sklearn.svm\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import color\n",
    "from PIL import Image \n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diretorio das imagens positivas\n",
    "pos_im_path = r\"./images/gadoP\" \n",
    "# diretorio das imagens negativas\n",
    "neg_im_path= r\"./images/gadoN\"\n",
    "\n",
    "# le as imagens\n",
    "pos_im_listing = os.listdir(pos_im_path)\n",
    "neg_im_listing = os.listdir(neg_im_path)\n",
    "num_pos_samples = len(pos_im_listing) \n",
    "num_neg_samples = len(neg_im_listing)\n",
    "# print do numero de imagens em cada dataset\n",
    "print(num_pos_samples)\n",
    "print(num_neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hog_images(img, hog_image):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 9), sharex=True, sharey=True)\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(img, cmap=plt.cm.gray)\n",
    "    ax1.set_title('Input image')\n",
    "\n",
    "    # Reescala o diagrama de gradientes para melhor visualização\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "    ax2.set_title('Histogram of Oriented Gradients')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ajust_img(img):\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    img = cv2.medianBlur(img, 9)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parametros do HoG\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "threshold = .3\n",
    "\n",
    "data= []\n",
    "labels = []\n",
    "\n",
    "def get_fd_hog_show(img):\n",
    "    img = ajust_img(img)\n",
    "    fd, hog = feature.hog(img, orientations, pixels_per_cell, cells_per_block,\n",
    "                        block_norm='L2', visualize=True, feature_vector=True)\n",
    "    show_hog_images(img, hog)\n",
    "    \n",
    "def get_fd_hog(img):\n",
    "    img = ajust_img(img)\n",
    "    fd = feature.hog(img, orientations, pixels_per_cell, cells_per_block,\n",
    "                        block_norm='L2', feature_vector=True)# fd= feature descriptor\n",
    "    return fd\n",
    "\n",
    "# computar HoG para as todas imagens positivas\n",
    "for file in pos_im_listing: \n",
    "    img = cv2.imread(pos_im_path + '/' + file) # abre o arquivo\n",
    "    fd = get_fd_hog(img)\n",
    "    data.append(fd)\n",
    "    labels.append(1)\n",
    "    \n",
    "# mostra a ultima imagem positiva com o HoG ao lado\n",
    "get_fd_hog_show(img)\n",
    "\n",
    "\n",
    "# computar HoG para as todas imagens negativas\n",
    "for file in neg_im_listing:\n",
    "    img= cv2.imread(neg_im_path + '/' + file) # abre o arquivo\n",
    "    fd = get_fd_hog(img)\n",
    "    data.append(fd)\n",
    "    labels.append(0)\n",
    "\n",
    "# mostra a ultima imagem negativa com o HoG ao lado\n",
    "get_fd_hog_show(img)\n",
    "    \n",
    "# codifca as labels, converte de string pra int\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img.shape\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criacao do modelo\n",
    "# usando 80% pra treino, e 20% pra teste\n",
    "print(\" Construindo modelo e seprandoo dataset ...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
    "\tnp.array(data), labels, test_size=0.20, random_state=42)\n",
    "# Treina SVM\n",
    "print(\" Treinando modelo SVM ...\")\n",
    "model = LinearSVC()\n",
    "model.fit(trainData, trainLabels)\n",
    "# Avalia o classificador\n",
    "print(\" Avaliando o classificador no teste ...\")\n",
    "predictions = model.predict(testData)\n",
    "print(classification_report(testLabels, predictions))\n",
    "\n",
    "\n",
    "# Save o modelo\n",
    "joblib.dump(model, 'model_bovinos.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa Modelo treinado\n",
    "\n",
    "# Parametros HOG\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "threshold = .3\n",
    "\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):# image is the input, step size is the no.of pixels needed to skip and windowSize is the size of the actual window\n",
    "    for y in range(0, image.shape[0], stepSize):# this line and the line below actually defines the sliding part and loops over the x and y coordinates\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            yield (x, y, image[y: y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "# Salva o modelo treinado\n",
    "model = joblib.load('model_bovinos.npy')\n",
    "\n",
    "# Teste do treino com uma imagem\n",
    "scale = 0\n",
    "detections = []\n",
    "img = cv2.imread(\"images/testP/135.png\") # open the file\n",
    "\n",
    "img = ajust_img(img)\n",
    "\n",
    "(winW, winH)= (64,128)\n",
    "windowSize=(winW,winH)\n",
    "downscale=1.5\n",
    "# Loop pra cada novo zoom na imagem\n",
    "for resized in pyramid_gaussian(img, downscale=1.5):\n",
    "    for (x,y,window) in sliding_window(resized, stepSize=10, windowSize=(winW,winH)):\n",
    "        # se a window n tiver o msm tamanho da imagem, ignorar\n",
    "        if window.shape[0] != winH or window.shape[1] !=winW:\n",
    "            continue\n",
    "        window=color.rgb2gray(window)\n",
    "        fds, hog = feature.hog(window, orientations, pixels_per_cell, cells_per_block, block_norm='L2')  # extract HOG features from the window captured\n",
    "        fds = fds.reshape(1, -1) # re shape the image to make a silouhette of hog\n",
    "        pred = model.predict(fds) # use the SVM model to make a prediction on the HOG features extracted from the window\n",
    "        \n",
    "        if pred == 1:\n",
    "            if model.decision_function(fds) > 0.6:  # set a threshold value for the SVM prediction i.e. only firm the predictions above probability of 0.6\n",
    "                print(\"Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                print(\"Scale ->  {} | Confidence Score {} \\n\".format(scale,model.decision_function(fds)))\n",
    "                detections.append((int(x * (downscale**scale)), int(y * (downscale**scale)), model.decision_function(fds),\n",
    "                                   int(windowSize[0]*(downscale**scale)), # create a list of all the predictions found\n",
    "                                      int(windowSize[1]*(downscale**scale))))\n",
    "    scale+=1\n",
    "    \n",
    "clone = resized.copy()\n",
    "for (x_tl, y_tl, _, w, h) in detections:\n",
    "    cv2.rectangle(img, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 255), thickness = 2)\n",
    "rects = np.array([[x, y, x + w, y + h] for (x, y, _, w, h) in detections]) # do nms on the detected bounding boxes\n",
    "sc = [score[0] for (x, y, score, w, h) in detections]\n",
    "print(\"detection confidence score: \", sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import image\n",
    "\n",
    "sc = np.array(sc)\n",
    "pick = image.non_max_suppression(rects, scores=sc, max_output_size=1, iou_threshold = 0.3)\n",
    "\n",
    "# cria a caixa verde em volta da detecção\n",
    "for (xA, yA, xB, yB) in pick:\n",
    "    cv2.rectangle(img, (xA, yA), (xB, yB), (0,255,0), 2)\n",
    "cv2.imshow(\"Raw Detections after NMS\", img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
